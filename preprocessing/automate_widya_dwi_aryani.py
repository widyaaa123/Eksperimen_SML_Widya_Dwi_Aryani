# -*- coding: utf-8 -*-
"""automate_Widya Dwi Aryani

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JrxgUudkp5QX-bmwz0_XTH83Z4Tn7KNu

# **1. Perkenalan Dataset**

Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagai berikut:

1. **Sumber Dataset**:  
   Dataset dapat diperoleh dari berbagai sumber, seperti public repositories (*Kaggle*, *UCI ML Repository*, *Open Data*) atau data primer yang Anda kumpulkan sendiri.

# **2. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning.
"""

#Library yang digunakan
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from yellowbrick.cluster import KElbowVisualizer
from google.colab import files
import joblib

"""# **3. Memuat Dataset**

Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.

Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.

Jika dataset berupa unstructured data, silakan sesuaikan dengan format seperti kelas Machine Learning Pengembangan atau Machine Learning Terapan
"""

#Load dataset
uploaded = files.upload()
df = pd.read_csv('financial_dataset.csv')
df.head()

"""# **4. Exploratory Data Analysis (EDA)**

Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.

Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan.
"""

df.info()

df.describe(include='all')

df.isnull().sum()

# Distribusi jumlah transaksi
sns.set(style="whitegrid")
plt.figure(figsize=(10,5))
sns.histplot(df['amount'], kde=True)
plt.title("Distribusi Jumlah Transaksi (Amount)")
plt.xlabel("Amount")
plt.ylabel("Frekuensi")
plt.show()

# Distribusi usia pelanggan
plt.figure(figsize=(10,5))
sns.histplot(df['customer_age'], kde=True, color='orange')
plt.title("Distribusi Usia Pelanggan")
plt.xlabel("Usia")
plt.ylabel("Frekuensi")
plt.show()

# Fraud vs Non-Fraud Count
plt.figure(figsize=(6,4))
sns.countplot(x='is_fraud', data=df)
plt.title("Perbandingan Fraud vs Non-Fraud")
plt.xlabel("0 = Non-Fraud | 1 = Fraud")
plt.ylabel("Jumlah")
plt.show()

# Top merchant category
plt.figure(figsize=(12,6))
df['merchant_category'].value_counts().head(5).plot(kind='bar')
plt.title("5 Merchant Category Teratas")
plt.xlabel("Kategori Merchant")
plt.ylabel("Jumlah Transaksi")
plt.show()

# Device Type Distribution
plt.figure(figsize=(8,5))
sns.countplot(x='device_type', data=df)
plt.title("Distribusi Device Type")
plt.xlabel("Device")
plt.ylabel("Jumlah")
plt.show()

# Korelasi Antar Fitur Numerik
plt.figure(figsize=(8,6))
sns.heatmap(df[['amount','customer_age','previous_transactions','is_fraud']].corr(),
            annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

"""# **5. Data Preprocessing**

Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.

Jika Anda menggunakan data teks, data mentah sering kali mengandung nilai kosong, duplikasi, atau rentang nilai yang tidak konsisten, yang dapat memengaruhi kinerja model. Oleh karena itu, proses ini bertujuan untuk membersihkan dan mempersiapkan data agar analisis berjalan optimal.

Berikut adalah tahapan-tahapan yang bisa dilakukan, tetapi **tidak terbatas** pada:
1. Menghapus atau Menangani Data Kosong (Missing Values)
2. Menghapus Data Duplikat
3. Normalisasi atau Standarisasi Fitur
4. Deteksi dan Penanganan Outlier
5. Encoding Data Kategorikal
6. Binning (Pengelompokan Data)

Cukup sesuaikan dengan karakteristik data yang kamu gunakan yah. Khususnya ketika kami menggunakan data tidak terstruktur.
"""

# Cek missing values
print("Missing values per kolom:")
print(df.isnull().sum())

# Cek jumlah duplikat
print("\nJumlah duplikat:", df.duplicated().sum())

# Konversi Timestamp Menjadi Datetime
df['timestamp'] = pd.to_datetime(df['timestamp'])

# Cek Outlier
plt.figure(figsize=(12,5))
sns.boxplot(data=df[['amount', 'previous_transactions']])
plt.title("Boxplot Amount & Previous Transactions")
plt.show()

# Penanganan Outlier
def handle_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    print(f"Before clipping, range: {df[column].min()} - {df[column].max()}")
    print(f"IQR Lower bound = {lower}, Upper bound = {upper}")

    # Clipping â†’ membatasi nilai agar tidak terlalu ekstrem
    df[column] = df[column].clip(lower, upper)

    print(f"After clipping, range: {df[column].min()} - {df[column].max()}")
    print("="*60)

# Terapkan ke kolom amount saja
handle_outliers_iqr(df, 'amount')

# Cek Ulang Boxplot Setelah Outlier Ditangani
plt.figure(figsize=(12,5))
sns.boxplot(data=df[['amount', 'previous_transactions']])
plt.title("Boxplot Setelah Penanganan Outlier")
plt.show()

# Encoding Data Kategorikal
df = pd.get_dummies(df,
                    columns=['merchant_category','customer_location','device_type'],
                    drop_first=True)

# Scaling Fitur Numerik
numeric_cols = ['amount','customer_age','previous_transactions']
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# Binning Usia Pelanggan
bins = [0, 25, 40, 60, 100]
labels = ['young','adult','middle_age','senior']
df['age_group'] = pd.cut(df['customer_age'], bins=bins, labels=labels)

#Menyimpan Hasil Pre-processing
df.to_csv('preprocessed_data.csv', index=False)
print('Data preprocessing telah berhasil disimpan ke preprocessed_data.csv')